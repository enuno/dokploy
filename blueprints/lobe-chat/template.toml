# LobeChat - AI Chat Platform
# https://github.com/lobehub/lobe-chat
#
# Modern AI chat interface with multi-provider support, knowledge base,
# plugins, and server-side database storage using PostgreSQL with pgvector.

[variables]
domain = "${domain}"
postgres_password = "${password:32}"
next_auth_secret = "${base64:32}"
key_vaults_secret = "${base64:32}"

[[config.domains]]
serviceName = "lobe-chat"
port = 3210
host = "${domain}"

[config.env]
# =============================================================================
# Domain Configuration
# =============================================================================
DOMAIN = "${domain}"

# =============================================================================
# Database Configuration
# =============================================================================
POSTGRES_DB = "lobechat"
POSTGRES_USER = "lobechat"
POSTGRES_PASSWORD = "${postgres_password}"

# =============================================================================
# Authentication & Security
# Generate secrets with: openssl rand -base64 32
# =============================================================================
NEXT_AUTH_SECRET = "${next_auth_secret}"
KEY_VAULTS_SECRET = "${key_vaults_secret}"

# Access code for basic protection (optional, comma-separated for multiple)
# Leave empty to allow unrestricted access (protected by auth anyway)
ACCESS_CODE = ""

# =============================================================================
# Cloudflare R2 Storage (Optional - for file uploads & knowledge base)
#
# To set up R2:
# 1. Go to Cloudflare Dashboard > R2 > Overview
# 2. Create a bucket (e.g., "lobechat-files")
# 3. Go to R2 > Manage R2 API Tokens
# 4. Create token with "Object Read & Write" permission
# 5. Copy Access Key ID and Secret Access Key
#
# Endpoint format: https://<ACCOUNT_ID>.r2.cloudflarestorage.com
# =============================================================================
S3_ENDPOINT = ""
S3_ACCESS_KEY_ID = ""
S3_SECRET_ACCESS_KEY = ""
S3_BUCKET = ""
S3_REGION = "auto"
S3_PUBLIC_DOMAIN = ""

# =============================================================================
# AI Provider API Keys (Configure at least one)
#
# Get API keys from:
# - OpenAI: https://platform.openai.com/api-keys
# - Anthropic: https://console.anthropic.com/settings/keys
# - Google: https://aistudio.google.com/app/apikey
# =============================================================================

# OpenAI (GPT-4, GPT-3.5, etc.)
OPENAI_API_KEY = ""
OPENAI_PROXY_URL = ""

# Anthropic (Claude)
ANTHROPIC_API_KEY = ""

# Google (Gemini)
GOOGLE_API_KEY = ""

# Azure OpenAI (if using Azure deployment)
AZURE_API_KEY = ""
AZURE_ENDPOINT = ""
AZURE_API_VERSION = ""

# Ollama (for local models - set to your Ollama server URL)
# Example: http://host.docker.internal:11434 or http://ollama:11434
OLLAMA_PROXY_URL = ""
