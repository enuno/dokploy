# OpenClaw - Personal AI Assistant

**OpenClaw** is a personal AI assistant that runs on your own devices. It integrates with the messaging channels you already use (WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, iMessage, Microsoft Teams, and more) and provides voice capabilities on macOS, iOS, and Android.

This is a production-ready Dokploy template featuring:

- ‚úÖ Official Docker image from GitHub Container Registry
- ‚úÖ Automatic HTTPS with LetsEncrypt
- ‚úÖ WebSocket gateway for real-time communication
- ‚úÖ Multi-channel messaging support
- ‚úÖ Voice capabilities and agent workspace
- ‚úÖ Secure token-based authentication
- ‚úÖ Full production deployment ready

## Features

### Multi-Channel Messaging
- **Direct Channels**: WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, iMessage, Microsoft Teams
- **Extension Channels**: BlueBubbles, Matrix, Zalo, and more
- **Live Canvas**: Visual agent-driven workspaces
- **Session Tools**: Inter-agent communication
- **Device Pairing**: Local actions on iOS/Android/macOS

### AI & Automation
- **Model Support**: Claude (Anthropic) recommended, OpenAI alternative
- **Multi-Agent Routing**: Isolated workspaces and sessions
- **Skills Platform**: Bundled, managed, and workspace-based extensions
- **Browser Control**: Dedicated Chromium instance
- **Voice Capabilities**: Voice Wake and Talk Mode

### Local-First Architecture
- üîí **Privacy-First**: Runs completely on your devices
- üöÄ **Fast**: Local execution, minimal latency
- üîå **Offline**: Works without cloud dependency
- üîê **Secure**: Your data stays under your control

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  openclaw-gateway    ‚îÇ
‚îÇ  (WebSocket + HTTP)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚îú‚îÄ Port 18789 (WebSocket) - Gateway control plane
        ‚îú‚îÄ Port 18790 (HTTP) - Dashboard/UI
        ‚îÇ
        ‚îú‚îÄ HTTPS (Traefik) - Secure external access
        ‚îÇ
        ‚îî‚îÄ Local volumes - Configuration & workspace
           ‚îú‚îÄ ~/.openclaw/workspace (agent workspace)
           ‚îî‚îÄ ~/.openclaw/openclaw.json (configuration)
```

## System Requirements

- **Docker & Docker Compose**: v2.x+
- **Network**: Stable internet connection
- **Memory**: Minimum 1GB RAM (2GB+ recommended)
- **Disk**: 2GB+ for workspace and cache
- **Model Access**: Claude API key or OpenAI API key

## Quick Start

### 1. Deploy the Template

In your Dokploy dashboard:

```bash
# Set environment variables:
OPENCLAW_DOMAIN=openclaw.your-domain.com
OPENCLAW_GATEWAY_TOKEN=<auto-generated 48-char base64>
ANTHROPIC_API_KEY=<your Claude API key>
```

### 2. First Run - Onboarding

After deployment, the gateway will be accessible at `https://openclaw.your-domain.com`

**Initial Setup:**
1. Access the dashboard
2. Authenticate with gateway token
3. Configure your model provider
4. Add messaging channels
5. Test with WhatsApp, Telegram, or other channels

### 3. Connect Messaging Channels

Each channel requires different setup. Visit https://docs.openclaw.ai/ for channel-specific instructions:

- **WhatsApp**: Scan QR code with WhatsApp
- **Telegram**: Create bot, set webhook
- **Slack**: Create app, install to workspace
- **Discord**: Create bot, add to server
- **Others**: Follow channel documentation

## Model Providers

OpenClaw supports multiple AI model providers. Choose one or configure fallback routing for resilience.

### Supported Providers

| Provider | Setup | Models | Best For | Pricing |
|----------|-------|--------|----------|---------|
| **Claude (Anthropic)** | https://console.anthropic.com | Claude 3 Opus, Sonnet, Haiku | General purpose, reasoning, code | $3-15/1M tokens |
| **OpenAI** | https://platform.openai.com/api-keys | GPT-4, GPT-4 Turbo, GPT-3.5 | State-of-the-art, reasoning | $0.03-0.03/1K tokens |
| **Mistral** | https://console.mistral.ai | Mistral Large, 8x7B, 7B | Fast inference, cost-effective | $0.24-2.4/1M tokens |
| **OpenRouter** | https://openrouter.ai | 100+ models (Claude, GPT-4, Mixtral, Llama 2) | Cost optimization, model variety, fallback routing | Variable |
| **Venice.ai** | https://venice.ai | Llama 2, Mistral, other open models | Privacy-first, cost-effective | Cheaper than proprietary |

### Setup Instructions

#### Claude (Anthropic) - Recommended for Quality

1. Go to https://console.anthropic.com/
2. Create an account or sign in
3. Navigate to **API Keys**
4. Click **Create Key**
5. Copy the API key
6. In Dokploy, set: `ANTHROPIC_API_KEY=sk-ant-...`

**Model Selection** (in agent configuration):
```
claude-3-opus-20240229      # Most capable
claude-3-sonnet-20240229    # Balanced
claude-3-haiku-20240307     # Fastest
```

#### OpenAI - GPT-4 Power

1. Go to https://platform.openai.com/api-keys
2. Create an account or sign in
3. Click **Create new secret key**
4. Copy the API key
5. In Dokploy, set: `OPENAI_API_KEY=sk-proj-...`

**Model Selection**:
```
gpt-4-turbo                 # Latest GPT-4 Turbo
gpt-4                       # Standard GPT-4
gpt-3.5-turbo              # Fast & cheap
```

#### Mistral - High Performance & Cost-Effective

**Why Mistral?**
- ‚úÖ Fast inference and excellent reasoning
- ‚úÖ Competitive pricing ($0.24-2.4/1M tokens)
- ‚úÖ Open weights option for local deployment
- ‚úÖ Great for multi-language support
- ‚úÖ Strong performance on code and reasoning tasks

**Setup:**

1. Go to https://console.mistral.ai
2. Sign up or log in with email
3. Navigate to **API Keys**
4. Click **Create new API key**
5. Copy the API key
6. In Dokploy, set: `MISTRAL_API_KEY=...`

**Model Selection**:
```
mistral-large              # Most powerful, best for complex tasks
mistral-8x7b              # Balanced performance and cost
mistral-7b                # Fastest and cheapest option
```

**Cost Comparison** (as of 2025):
```
Mistral Large: $2.4/1M input, $7.2/1M output tokens
Mistral 8x7B:  $0.27/1M input, $0.81/1M output tokens
Mistral 7B:    $0.14/1M input, $0.42/1M output tokens
```

#### OpenRouter - Best for Flexibility

**Why OpenRouter?**
- ‚úÖ 100+ models in one API
- ‚úÖ Automatic fallback routing if primary model fails
- ‚úÖ Unified billing across multiple providers
- ‚úÖ Usage analytics and comparison
- ‚úÖ No per-model setup needed

**Setup:**

1. Go to https://openrouter.ai
2. Sign up with email or GitHub
3. Go to **Keys** in the dashboard
4. Click **Create New Key**
5. Copy the API key
6. In Dokploy, set: `OPENROUTER_API_KEY=sk-or-...`

**Popular Model Options:**

```
# OpenAI models (via OpenRouter)
openai/gpt-4-turbo
openai/gpt-4
openai/gpt-3.5-turbo

# Anthropic models (via OpenRouter)
anthropic/claude-3-opus
anthropic/claude-3-sonnet
anthropic/claude-3-haiku

# Open source (via OpenRouter)
mistralai/mixtral-8x7b
meta-llama/llama-2-70b-chat
nousresearch/nous-hermes-2-mixtral-8x7b

# Cost-effective options
nousresearch/nous-hermes-2-mixtral-8x7b  # ~$0.24/M tokens
meta-llama/llama-2-70b-chat               # ~$0.72/M tokens
```

**Enable Fallback Routing** (in OpenRouter dashboard):
- Set primary model (e.g., Claude Opus)
- Add fallback models (e.g., GPT-4, Mixtral)
- OpenRouter automatically switches if one fails

#### Venice.ai - Privacy-First & Cost-Effective

**Why Venice.ai?**
- ‚úÖ Privacy-first - no data retention
- ‚úÖ GDPR & privacy compliant
- ‚úÖ Cheaper than proprietary APIs
- ‚úÖ Multiple open models available
- ‚úÖ European servers

**Setup:**

1. Go to https://venice.ai
2. Sign up for account
3. Navigate to **API Keys**
4. Create a new API key
5. In Dokploy, set: `VENICE_API_KEY=...`

**Available Models:**

```
# Open source models
llama-2-70b-chat           # Meta's Llama 2
mistral-7b                 # Mistral 7B
mistral-medium             # Mistral Medium
neural-chat-7b             # Neural Chat
dolphin-2.5                # Dolphin 2.5
```

### Environment Configuration

#### Required Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `OPENCLAW_DOMAIN` | None | Your domain for the gateway (e.g., openclaw.example.com) |
| `OPENCLAW_GATEWAY_TOKEN` | Auto-gen | Secure token for gateway authentication (48-char base64) |

#### Optional Variables (Choose One Provider)

| Variable | Setup Link | Description |
|----------|-----------|-------------|
| `ANTHROPIC_API_KEY` | https://console.anthropic.com | Claude API key (recommended for quality) |
| `OPENAI_API_KEY` | https://platform.openai.com/api-keys | OpenAI API key (GPT-4) |
| `MISTRAL_API_KEY` | https://console.mistral.ai | Mistral API key (fast, cost-effective) |
| `OPENROUTER_API_KEY` | https://openrouter.ai | OpenRouter key (multi-model, fallback routing) |
| `VENICE_API_KEY` | https://venice.ai | Venice.ai key (privacy-first, cost-effective) |

#### Optional Configuration

| Variable | Default | Description |
|----------|---------|-------------|
| `DEBUG` | false | Enable debug logging |
| `LOG_LEVEL` | info | Logging level (debug, info, warn, error) |

### Gateway Configuration

These are automatically configured:
- `OPENCLAW_GATEWAY_HOST`: `0.0.0.0` (listen on all interfaces)
- `OPENCLAW_GATEWAY_PORT`: `18789` (WebSocket port - internal)

## Security & Authentication

### Gateway Token
- Generated automatically during deployment (48-char base64)
- Required for all WebSocket connections
- Never share publicly or commit to version control

### Model Provider Authentication
- **Claude**: API key from https://console.anthropic.com
- **OpenAI**: API key from https://platform.openai.com/api-keys
- Keep API keys secure - never expose in logs or UI

### Channel Credentials
Each messaging channel stores credentials securely:
- WhatsApp sessions stored encrypted
- Telegram bot tokens in secure storage
- Slack OAuth tokens encrypted
- Discord bot tokens encrypted

### Network Security
- HTTPS-only access via Traefik
- LetsEncrypt automatic SSL certificates
- Gateway token-based authentication
- Optional: Cloudflare Tunnel for private access

## Messaging Channel Setup

### WhatsApp
```
1. Go to dashboard https://openclaw.your-domain.com
2. Navigate to Channels ‚Üí WhatsApp
3. Scan QR code with WhatsApp mobile app
4. Authenticate device
5. Start chatting!
```

### Telegram
```
1. Create bot: @BotFather on Telegram
2. Get bot token
3. Copy token to dashboard ‚Üí Channels ‚Üí Telegram
4. Set webhook: https://openclaw.your-domain.com/webhook/telegram
5. Start chatting with your bot
```

### Slack
```
1. Create Slack app at https://api.slack.com/apps
2. Enable Socket Mode
3. Get App Token
4. Copy to dashboard ‚Üí Channels ‚Üí Slack
5. Install app to workspace
6. Invite bot to channels
```

### Discord
```
1. Create bot at https://discord.com/developers/applications
2. Get bot token
3. Copy token to dashboard ‚Üí Channels ‚Üí Discord
4. Get server invite URL
5. Add bot to your Discord server
6. Start chatting!
```

See https://docs.openclaw.ai/channels/ for all 13+ supported channels.

## Voice Capabilities

### macOS & iOS
- **Voice Wake**: "Hey OpenClaw" wake word detection
- **Talk Mode**: Continuous voice conversation
- **Audio Processing**: Local, on-device speech processing

### Android
- Voice integration through BlueBubbles integration
- Full voice support coming in future releases

### Configuration
Enable in dashboard:
```
Settings ‚Üí Voice ‚Üí Enable Voice Wake
Settings ‚Üí Voice ‚Üí Language (en-US, etc.)
Settings ‚Üí Voice ‚Üí Wake Word Sensitivity
```

## Advanced Configuration

### Custom Storage Location

By default, workspace data is stored in:
- `~/.openclaw/workspace` - Agent files and data
- `~/.openclaw/openclaw.json` - Configuration

To change (optional):
```bash
# Edit docker-compose.yml volumes:
volumes:
  - /custom/path/workspace:/root/.openclaw/workspace
  - /custom/path/config:/root/.openclaw
```

### Remote Access via Cloudflare Tunnel

For private access without exposing to internet:

```bash
# Optional: Set up Cloudflare Tunnel
# See Cloudflare setup guide below
```

### Multi-Workspace Setup

For multiple independent instances:
1. Deploy separate Dokploy template for each
2. Use unique domains for each instance
3. Use separate workspace directories
4. Manage separately in dashboard

## Cloudflare Tunnel (Optional)

If you want secure remote access without exposing to the public internet:

### Create Cloudflare Tunnel

```bash
# Install cloudflared
brew install cloudflare/cloudflare/cloudflared  # macOS
# or download from https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/install-and-setup/tunnel-guide/local/

# Create tunnel
cloudflared tunnel create openclaw

# Get tunnel credentials (token)
cloudflared tunnel list
```

### Configure in Dokploy

Instead of using Traefik routing, use the Tunnel:

1. Add tunnel token to environment:
```
TUNNEL_TOKEN=<your tunnel token>
```

2. (Optional) Update docker-compose to use cloudflared service

3. Verify tunnel is running:
```bash
cloudflared tunnel route dns openclaw openclaw.your-domain.com
```

Benefits:
- ‚úÖ Private access - no public IP needed
- ‚úÖ Encrypted by default
- ‚úÖ No port forwarding required
- ‚úÖ Works behind NAT/firewall

## Monitoring & Logging

### Dashboard
- Real-time connection status
- Message logs per channel
- Agent activity logs
- System health metrics

### Logs
```bash
# View gateway logs
docker compose logs openclaw-gateway -f

# View specific time range
docker compose logs openclaw-gateway --since 1h
```

### Health Check
```bash
# Check gateway health
curl https://openclaw.your-domain.com/health

# Expected response
{"status":"healthy","version":"0.9.0"}
```

## Troubleshooting

### Gateway Not Starting
**Symptom**: Connection refused on port 18789

**Solutions**:
1. Check Docker Compose logs: `docker compose logs openclaw-gateway`
2. Verify `OPENCLAW_GATEWAY_TOKEN` is set
3. Check port 18789 is not in use: `lsof -i :18789`
4. Ensure 2GB+ memory available

### Channel Connection Issues

**WhatsApp**: "Session expired"
- Solution: Re-scan QR code in dashboard
- WhatsApp sessions expire after 90 days of inactivity

**Telegram**: "Webhook not responding"
- Solution: Verify domain DNS is correct
- Check firewall allows HTTPS on 443
- Verify Telegram webhook URL in settings

**Slack**: "Invalid token"
- Solution: Generate new token at https://api.slack.com/apps
- Copy new token to dashboard

### Message Delivery Issues

**No messages appearing**:
1. Check channel is connected: Dashboard ‚Üí Channels
2. Check agent status: Dashboard ‚Üí Agents
3. Review logs: `docker compose logs openclaw-gateway`
4. Verify model provider is working: Test API key

**Slow responses**:
1. Check network latency to gateway
2. Monitor API provider rate limits
3. Check local system resources (CPU, memory)
4. Consider upgrading API tier if rate-limited

### SSL Certificate Issues

**Error: "Certificate not trusted"**
- LetsEncrypt certificate takes ~5 minutes after deployment
- Wait for certificate provisioning
- Clear browser cache and try again

**Error: "acme: error: malformed"**
- Verify domain DNS points to server IP
- Check domain has no CNAME conflicts

### Remote Access Issues

**Can't connect via Cloudflare Tunnel**:
```bash
# Test tunnel locally
cloudflared access

# Check tunnel status
cloudflared tunnel status openclaw

# View tunnel logs
cloudflared tunnel run openclaw
```

## Performance Tuning

### Response Time Optimization
- GPU acceleration available (if supported)
- Increase model context window for better responses
- Use faster model variant (Claude 3 Haiku vs Opus)

### Network Optimization
- Deploy geographically close to users
- Consider Cloudflare CDN for static assets
- Use local DNS caching

### Resource Limits
```yaml
deploy:
  resources:
    limits:
      memory: 2G  # Increase if needed
      cpus: "2"
```

## Updates & Maintenance

### Check for Updates
```bash
# View current version
docker compose logs openclaw-gateway | grep version

# Check latest available
docker pull ghcr.io/openclaw/openclaw:latest
```

### Update to Latest Version
```bash
# Update docker-compose.yml image tag
# image: ghcr.io/openclaw/openclaw:latest

docker compose pull
docker compose up -d openclaw-gateway
```

### Backup Configuration
```bash
# Backup workspace and config
docker compose exec openclaw-gateway tar -czf - ~/.openclaw | tar -xzf - -C /backup/

# Or using volumes
cp -r ~/.openclaw /backup/openclaw-$(date +%Y%m%d)
```

## Disaster Recovery

### Restore from Backup
```bash
# Stop gateway
docker compose stop openclaw-gateway

# Restore configuration
cp -r /backup/openclaw/* ~/.openclaw/

# Restart gateway
docker compose up -d openclaw-gateway
```

### Workspace Recovery
If workspace directory is lost:
1. Restart gateway - empty workspace created
2. Re-authorize messaging channels
3. Agents will restore from channel history
4. History visible in dashboard

## Development & Customization

### Skills Development
Create custom skills in your workspace:
```
~/.openclaw/workspace/skills/
  ‚îú‚îÄ‚îÄ my-skill/
  ‚îÇ   ‚îú‚îÄ‚îÄ index.js
  ‚îÇ   ‚îú‚îÄ‚îÄ manifest.json
  ‚îÇ   ‚îî‚îÄ‚îÄ README.md
```

### Custom Integrations
Extend with custom agents:
```bash
# Add agent via dashboard
Settings ‚Üí Agents ‚Üí Add Custom Agent
```

### API Access
Access gateway via REST API:
```bash
curl -H "Authorization: Bearer $OPENCLAW_GATEWAY_TOKEN" \
  https://openclaw.your-domain.com/api/agents
```

## Support & Resources

### Official Documentation
- **Full Docs**: https://docs.openclaw.ai/
- **GitHub**: https://github.com/openclaw/openclaw
- **Issues**: https://github.com/openclaw/openclaw/issues

### Community
- **Discord**: https://discord.gg/openclaw
- **Discussions**: https://github.com/openclaw/openclaw/discussions

### API Documentation
- **Gateway API**: https://docs.openclaw.ai/api/
- **WebSocket Protocol**: https://docs.openclaw.ai/websocket/

## License

OpenClaw is MIT licensed - see https://github.com/openclaw/openclaw/blob/main/LICENSE

## Deployment Notes

### Dokploy Integration
- ‚úÖ Automatic HTTPS with LetsEncrypt
- ‚úÖ Docker Compose orchestration
- ‚úÖ Health checks configured
- ‚úÖ Traefik reverse proxy included
- ‚úÖ Volume persistence included

### Recommended Specifications
| Resource | Minimum | Recommended | Large Scale |
|----------|---------|-------------|-------------|
| RAM | 1GB | 2GB | 4GB+ |
| CPU | 1 core | 2 cores | 4+ cores |
| Storage | 2GB | 10GB | 50GB+ |
| Network | 5 Mbps | 25 Mbps | 100+ Mbps |

### Network Ports
- `18789` (WebSocket) - Internal gateway communication
- `18790` (HTTP) - Dashboard & health checks
- `443` (HTTPS) - External access via Traefik/domain
- `80` (HTTP) - LetsEncrypt ACME challenges

### First Deployment Checklist
- [ ] Domain DNS configured
- [ ] ANTHROPIC_API_KEY or OPENAI_API_KEY obtained
- [ ] OPENCLAW_GATEWAY_TOKEN generated
- [ ] Dokploy instance has 2GB+ RAM
- [ ] Network allows HTTPS (443) outbound for API calls
- [ ] Firewall allows HTTPS (443) inbound for HTTPS access

## Changelog

### v0.9.0 (Current)
- Multi-channel messaging support
- Voice capabilities for macOS/iOS
- Live Canvas workspace
- Skills platform
- Browser control integration
- Full production deployment ready
